##è¿™æ˜¯ä¸ªéå¸¸å…³é”®çš„é—®é¢˜ã€‚åœ¨çŸ¥è¯†è’¸é¦ï¼ˆdistillationï¼‰ä¸­å¼•å…¥ softmax çš„æ¸©åº¦ç³»æ•° Tï¼ˆtemperatureï¼‰æ—¶ï¼Œå¦‚æœä½ å¸Œæœ›æ¢¯åº¦æ­£ç¡®ä¼ æ’­ï¼Œè®­ç»ƒæ—¶éœ€è¦ç‰¹åˆ«æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š
##
##ğŸ§  èƒŒæ™¯å›é¡¾ï¼šä»€ä¹ˆæ˜¯ Temperature Tï¼Ÿ
##softmax(logits / T) ç”¨äºæ§åˆ¶è¾“å‡ºåˆ†å¸ƒçš„â€œå¹³æ»‘ç¨‹åº¦â€ï¼š
##T = 1ï¼šæ­£å¸¸ softmaxã€‚
##T > 1ï¼šè¾“å‡ºåˆ†å¸ƒæ›´å¹³æ»‘ï¼Œå·®å¼‚æ›´å°ã€‚
##T < 1ï¼šè¾“å‡ºåˆ†å¸ƒæ›´å°–é”ã€‚
##
##åœ¨çŸ¥è¯†è’¸é¦ä¸­ï¼Œä¸€èˆ¬è®¾ç½® T = 2 ~ 10ã€‚
##
##âœ… è®­ç»ƒæ—¶è®¡ç®—è’¸é¦æŸå¤±æ—¶çš„æ³¨æ„ç‚¹
##ä½ é€šå¸¸ä¼šæœ‰ä¸¤ä¸ª lossï¼š
##
##loss_ceï¼šäº¤å‰ç†µæŸå¤±ï¼ˆçœŸå®æ ‡ç­¾ä¸ student è¾“å‡ºä¹‹é—´ï¼‰
##
##loss_kdï¼šè’¸é¦æŸå¤±ï¼ˆstudent ä¸ teacher soft logits å¯¹æ¯”ï¼‰
##
##å…¶ä¸­ è’¸é¦æŸå¤±å¸¸è§å½¢å¼æ˜¯ KL æ•£åº¦ï¼š
##
##loss_kd = KLDivLoss(
##    log_softmax(student_logits / T),
##    softmax(teacher_logits / T)
##) * (T * T)
##âœ… ä¸ºä»€ä¹ˆè¦ä¹˜ (T * T)ï¼Ÿ
##è¿™ä¸€æ­¥éå¸¸é‡è¦ï¼Œæ˜¯ä¸ºäº†ç¡®ä¿æ¢¯åº¦çš„ scale ä¿æŒä¸€è‡´ã€‚
##
##ğŸ“Œ æ•°å­¦æ¨å¯¼æ ¸å¿ƒ
##å½“ä½ å¯¹ softmax(logits / T) åšåå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦ä¼šè¢«ç¼©å° 1 / T^2ã€‚
##
##ä¸ºäº†è¡¥å¿è¿™ä¸ªæ¢¯åº¦ç¼©å°ï¼Œä½ éœ€è¦åœ¨ loss å¤–å±‚ä¹˜ä¸Š T^2ã€‚
##
##å¦åˆ™ï¼š
##Temperature å˜å¤§ä¼šè®© loss çœ‹èµ·æ¥æ›´å°ï¼›
##ä½†å®é™…å½±å“äº†æ¢¯åº¦æ–¹å‘ï¼Œè®­ç»ƒå°±ä¼šå¤±æ•ˆã€‚
##
##âœ… PyTorch å®ç°ç¤ºä¾‹ï¼ˆå¯è¿è¡Œï¼‰
##
##import torch
##import torch.nn.functional as F
##
##def distillation_loss(student_logits, teacher_logits, labels, T=4.0, alpha=0.5):
##    # Cross Entropy (çœŸå®æ ‡ç­¾)
##    loss_ce = F.cross_entropy(student_logits, labels)
##
##    # è’¸é¦ lossï¼šKL divergence between softened probs
##    student_soft = F.log_softmax(student_logits / T, dim=1)
##    teacher_soft = F.softmax(teacher_logits / T, dim=1)
##
##    loss_kd = F.kl_div(student_soft, teacher_soft, reduction='batchmean') * (T * T)
##
##    # æ€» loss = è’¸é¦ + çœŸå®æ ‡ç­¾äº¤å‰ç†µ
##    return alpha * loss_kd + (1 - alpha) * loss_ce
##
##ğŸ§ª ç”¨æ³•ç¤ºä¾‹
##
##student_logits = student_model(input_ids)
##with torch.no_grad():
##    teacher_logits = teacher_model(input_ids)
##
##loss = distillation_loss(student_logits, teacher_logits, labels, T=4.0, alpha=0.7)
##loss.backward()
##
##âœ… æ€»ç»“ï¼šè®­ç»ƒæ—¶å¿…é¡»åšçš„æ“ä½œ
##æ­¥éª¤	æ“ä½œ
##1	å¯¹ logits åš softmax/log_softmax æ—¶é™¤ä»¥ T
##2	loss å¤–éƒ¨ä¹˜ä»¥ T^2 è¿›è¡Œæ¢¯åº¦ç¼©æ”¾è¡¥å¿
##3	ç”¨ alpha æ§åˆ¶ soft loss ä¸ hard loss çš„åŠ æƒ
##
###------------------------------------------------------------------------
##distillation, softmax ä¸­çš„tempreture T, åœ¨inferenceæ—¶ï¼Œéœ€è¦åšå•¥ç‰¹åˆ«æ“ä½œï¼Ÿ
##
##ç»“è®ºï¼ˆç®€æ´ç‰ˆï¼‰ï¼š
##æ¨ç†æ—¶ ä¸è¦ä½¿ç”¨é«˜æ¸©åº¦ Tï¼Œåªä½¿ç”¨æ­£å¸¸çš„ softmax(logits) æˆ– argmax(logits) æ¥åšé¢„æµ‹ã€‚
##
##ğŸ§  ä¸ºä»€ä¹ˆè®­ç»ƒæ—¶è¦ç”¨ Tï¼Œè€Œæ¨ç†æ—¶ä¸ç”¨ï¼Ÿ
##é˜¶æ®µ	Temperature T	                ç”¨é€”è¯´æ˜
##è®­ç»ƒé˜¶æ®µ	T > 1	                å¹³æ»‘ teacher/student çš„ soft label åˆ†å¸ƒï¼Œä½¿ student èƒ½å­¦ä¹  teacher çš„çŸ¥è¯†ç»“æ„ï¼ˆç»†ç²’åº¦ç›¸ä¼¼åº¦ï¼‰
##æ¨ç†é˜¶æ®µ	T = 1	                ç›´æ¥è¾“å‡ºåˆ†ç±»ç»“æœï¼Œä¸éœ€è¦çŸ¥è¯†å¹³æ»‘ï¼Œç›®æ ‡æ˜¯åšæœ€ç»ˆå†³ç­–
##
##âœ… æ¨ç†ä»£ç å¯¹æ¯”ï¼š
##âœ… æ¨ç†æ—¶ï¼šæ­£å¸¸ softmax
##
##logits = student_model(input_ids)
##probs = torch.softmax(logits, dim=-1)
##pred = torch.argmax(probs, dim=-1)
##æˆ–è€…ç”šè‡³æ›´ç®€å•ï¼š
##
##pred = torch.argmax(logits, dim=-1)
##ğŸš« ä¸è¦å†åšè¿™ä¸ªï¼ˆè®­ç»ƒç”¨ï¼‰ï¼š
##
### âŒ è¿™æ˜¯è®­ç»ƒç”¨çš„é«˜æ¸© softmaxï¼Œä¸é€‚åˆ inference
##probs = torch.softmax(logits / T, dim=-1)
##ğŸ” ä¸¾ä¸ªä¾‹å­
##è®­ç»ƒæ—¶ç”¨ T = 4ï¼š
##
### è®­ç»ƒé˜¶æ®µ
##teacher_probs = softmax(teacher_logits / 4.0)
##student_probs = softmax(student_logits / 4.0)
##ä½† æ¨ç†é˜¶æ®µï¼Œåªéœ€è¦ï¼š
##
### æ¨ç†é˜¶æ®µ
##pred = torch.argmax(student_logits, dim=-1)
##ğŸ§¾ æ€»ç»“
##é˜¶æ®µ  	        softmax(logits / T)	        æ˜¯å¦ä¹˜ä»¥ TÂ²	               ç”¨é€”
##è®­ç»ƒï¼ˆè’¸é¦ï¼‰  	    âœ…ï¼ˆT > 1ï¼‰	            âœ…ï¼ˆä¸ºäº†æ¢¯åº¦æ­£ç¡®ï¼‰	        è·å– soft target + å¹³æ»‘è®­ç»ƒ
##æ¨ç†	                âŒï¼ˆç›´æ¥ç”¨ logitsï¼‰   	âŒ	                    è¾“å‡ºé¢„æµ‹ç±»åˆ«

##--------------------------------------------------------------------
https://zhuanlan.zhihu.com/p/102038521
4.2. æ¸©åº¦ä»£è¡¨äº†ä»€ä¹ˆï¼Œå¦‚ä½•é€‰å–åˆé€‚çš„æ¸©åº¦ï¼Ÿ
æ¸©åº¦çš„é«˜ä½æ”¹å˜çš„æ˜¯Net-Sè®­ç»ƒè¿‡ç¨‹ä¸­å¯¹è´Ÿæ ‡ç­¾çš„å…³æ³¨ç¨‹åº¦: æ¸©åº¦è¾ƒä½æ—¶ï¼Œå¯¹è´Ÿæ ‡ç­¾çš„å…³æ³¨ï¼Œå°¤å…¶æ˜¯é‚£äº›æ˜¾è‘—ä½äºå¹³å‡å€¼çš„è´Ÿæ ‡ç­¾çš„å…³æ³¨è¾ƒå°‘ï¼›è€Œæ¸©åº¦è¾ƒé«˜æ—¶ï¼Œè´Ÿæ ‡ç­¾ç›¸å…³çš„å€¼ä¼šç›¸å¯¹å¢å¤§ï¼ŒNet-Sä¼šç›¸å¯¹å¤šåœ°å…³æ³¨åˆ°è´Ÿæ ‡ç­¾ã€‚

å®é™…ä¸Šï¼Œè´Ÿæ ‡ç­¾ä¸­åŒ…å«ä¸€å®šçš„ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯é‚£äº›å€¼æ˜¾è‘—é«˜äºå¹³å‡å€¼çš„è´Ÿæ ‡ç­¾ã€‚ä½†ç”±äºNet-Tçš„è®­ç»ƒè¿‡ç¨‹å†³å®šäº†è´Ÿæ ‡ç­¾éƒ¨åˆ†æ¯”è¾ƒnoisyï¼Œå¹¶ä¸”è´Ÿæ ‡ç­¾çš„å€¼è¶Šä½ï¼Œå…¶ä¿¡æ¯å°±è¶Šä¸å¯é ã€‚å› æ­¤æ¸©åº¦çš„é€‰å–æ¯”è¾ƒempiricalï¼Œæœ¬è´¨ä¸Šå°±æ˜¯åœ¨ä¸‹é¢ä¸¤ä»¶äº‹ä¹‹ä¸­å–èˆ:

ä»æœ‰éƒ¨åˆ†ä¿¡æ¯é‡çš„è´Ÿæ ‡ç­¾ä¸­å­¦ä¹  --> æ¸©åº¦è¦é«˜ä¸€äº›
é˜²æ­¢å—è´Ÿæ ‡ç­¾ä¸­å™ªå£°çš„å½±å“ -->æ¸©åº¦è¦ä½ä¸€äº›
æ€»çš„æ¥è¯´ï¼ŒTçš„é€‰æ‹©å’ŒNet-Sçš„å¤§å°æœ‰å…³ï¼ŒNet-Så‚æ•°é‡æ¯”è¾ƒå°çš„æ—¶å€™ï¼Œç›¸å¯¹æ¯”è¾ƒä½çš„æ¸©åº¦å°±å¯ä»¥äº†ï¼ˆå› ä¸ºå‚æ•°é‡å°çš„æ¨¡å‹ä¸èƒ½capture all knowledgeï¼Œæ‰€ä»¥å¯ä»¥é€‚å½“å¿½ç•¥æ‰ä¸€äº›è´Ÿæ ‡ç­¾çš„ä¿¡æ¯ï¼‰

##--------------------------------------------------------------------
https://zhuanlan.zhihu.com/p/71986772

1.2 è’¸é¦æ—¶çš„softmax

æ¯”ä¹‹å‰çš„softmaxå¤šäº†ä¸€ä¸ªå‚æ•°Tï¼ˆtemperatureï¼‰ï¼ŒTè¶Šå¤§äº§ç”Ÿçš„æ¦‚ç‡åˆ†å¸ƒè¶Šå¹³æ»‘ã€‚

æœ‰ä¸¤ç§è’¸é¦çš„ç›®æ ‡å‡½æ•°ï¼š
1. åªä½¿ç”¨soft targetsï¼šåœ¨è’¸é¦æ—¶teacherä½¿ç”¨æ–°çš„softmaxäº§ç”Ÿsoft targetsï¼›studentä½¿ç”¨æ–°çš„softmaxåœ¨transfer setä¸Šå­¦ä¹ ï¼Œå’Œteacherä½¿ç”¨ç›¸åŒçš„Tã€‚
2. åŒæ—¶ä½¿ç”¨sotfå’Œhard targetsï¼šstudentçš„ç›®æ ‡å‡½æ•°æ˜¯hard targetå’Œsoft targetç›®æ ‡å‡½æ•°çš„åŠ æƒå¹³å‡ï¼Œä½¿ç”¨hard targetæ—¶T=1ï¼Œsoft targetæ—¶Tå’Œteacherçš„ä¸€æ ·ã€‚Hintonçš„ç»éªŒæ˜¯ç»™hard targetçš„æƒé‡å°ä¸€ç‚¹ã€‚å¦å¤–è¦æ³¨æ„çš„æ˜¯ï¼Œå› ä¸ºåœ¨æ±‚æ¢¯åº¦ï¼ˆå¯¼æ•°ï¼‰æ—¶æ–°çš„ç›®æ ‡å‡½æ•°ä¼šå¯¼è‡´æ¢¯åº¦æ˜¯ä»¥å‰çš„
1/T^2 ï¼Œæ‰€ä»¥è¦å†ä¹˜ä¸Š T^2 ï¼Œä¸ç„¶Tå˜äº†çš„è¯hard targetä¸å‡å°ï¼ˆT=1ï¼‰ï¼Œä½†soft targetä¼šå˜ã€‚
3. ç›´æ¥ç”¨logitsçš„MSEï¼ˆæ˜¯1çš„special caseï¼‰

