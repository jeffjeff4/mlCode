##这是个非常关键的问题。在知识蒸馏（distillation）中引入 softmax 的温度系数 T（temperature）时，如果你希望梯度正确传播，训练时需要特别注意以下几点：
##
##🧠 背景回顾：什么是 Temperature T？
##softmax(logits / T) 用于控制输出分布的“平滑程度”：
##T = 1：正常 softmax。
##T > 1：输出分布更平滑，差异更小。
##T < 1：输出分布更尖锐。
##
##在知识蒸馏中，一般设置 T = 2 ~ 10。
##
##✅ 训练时计算蒸馏损失时的注意点
##你通常会有两个 loss：
##
##loss_ce：交叉熵损失（真实标签与 student 输出之间）
##
##loss_kd：蒸馏损失（student 与 teacher soft logits 对比）
##
##其中 蒸馏损失常见形式是 KL 散度：
##
##loss_kd = KLDivLoss(
##    log_softmax(student_logits / T),
##    softmax(teacher_logits / T)
##) * (T * T)
##✅ 为什么要乘 (T * T)？
##这一步非常重要，是为了确保梯度的 scale 保持一致。
##
##📌 数学推导核心
##当你对 softmax(logits / T) 做反向传播时，梯度会被缩小 1 / T^2。
##
##为了补偿这个梯度缩小，你需要在 loss 外层乘上 T^2。
##
##否则：
##Temperature 变大会让 loss 看起来更小；
##但实际影响了梯度方向，训练就会失效。
##
##✅ PyTorch 实现示例（可运行）
##
##import torch
##import torch.nn.functional as F
##
##def distillation_loss(student_logits, teacher_logits, labels, T=4.0, alpha=0.5):
##    # Cross Entropy (真实标签)
##    loss_ce = F.cross_entropy(student_logits, labels)
##
##    # 蒸馏 loss：KL divergence between softened probs
##    student_soft = F.log_softmax(student_logits / T, dim=1)
##    teacher_soft = F.softmax(teacher_logits / T, dim=1)
##
##    loss_kd = F.kl_div(student_soft, teacher_soft, reduction='batchmean') * (T * T)
##
##    # 总 loss = 蒸馏 + 真实标签交叉熵
##    return alpha * loss_kd + (1 - alpha) * loss_ce
##
##🧪 用法示例
##
##student_logits = student_model(input_ids)
##with torch.no_grad():
##    teacher_logits = teacher_model(input_ids)
##
##loss = distillation_loss(student_logits, teacher_logits, labels, T=4.0, alpha=0.7)
##loss.backward()
##
##✅ 总结：训练时必须做的操作
##步骤	操作
##1	对 logits 做 softmax/log_softmax 时除以 T
##2	loss 外部乘以 T^2 进行梯度缩放补偿
##3	用 alpha 控制 soft loss 与 hard loss 的加权
##
###------------------------------------------------------------------------
##distillation, softmax 中的tempreture T, 在inference时，需要做啥特别操作？
##
##结论（简洁版）：
##推理时 不要使用高温度 T，只使用正常的 softmax(logits) 或 argmax(logits) 来做预测。
##
##🧠 为什么训练时要用 T，而推理时不用？
##阶段	Temperature T	                用途说明
##训练阶段	T > 1	                平滑 teacher/student 的 soft label 分布，使 student 能学习 teacher 的知识结构（细粒度相似度）
##推理阶段	T = 1	                直接输出分类结果，不需要知识平滑，目标是做最终决策
##
##✅ 推理代码对比：
##✅ 推理时：正常 softmax
##
##logits = student_model(input_ids)
##probs = torch.softmax(logits, dim=-1)
##pred = torch.argmax(probs, dim=-1)
##或者甚至更简单：
##
##pred = torch.argmax(logits, dim=-1)
##🚫 不要再做这个（训练用）：
##
### ❌ 这是训练用的高温 softmax，不适合 inference
##probs = torch.softmax(logits / T, dim=-1)
##🔍 举个例子
##训练时用 T = 4：
##
### 训练阶段
##teacher_probs = softmax(teacher_logits / 4.0)
##student_probs = softmax(student_logits / 4.0)
##但 推理阶段，只需要：
##
### 推理阶段
##pred = torch.argmax(student_logits, dim=-1)
##🧾 总结
##阶段  	        softmax(logits / T)	        是否乘以 T²	               用途
##训练（蒸馏）  	    ✅（T > 1）	            ✅（为了梯度正确）	        获取 soft target + 平滑训练
##推理	                ❌（直接用 logits）   	❌	                    输出预测类别
