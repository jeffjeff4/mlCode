import numpy as np
import faiss  # pip install faiss-cpu

# è®¾ç½®éšæœºç§å­
np.random.seed(42)

# -------------------------------
# Step 1: æ„é€ å‘é‡åº“å’ŒæŸ¥è¯¢å‘é‡
# -------------------------------
num_vectors = 10000
vector_dim = 128
num_queries = 5

# æ¨¡æ‹Ÿ embedding
database_vectors = np.random.randn(num_vectors, vector_dim).astype(np.float32)
query_vectors = np.random.randn(num_queries, vector_dim).astype(np.float32)

# -------------------------------
# Step 2: æ„å»ºä¸åŒ ANN ç´¢å¼•
# -------------------------------

# IVFï¼ˆèšç±»é‡åŒ–ï¼‰
nlist = 100  # èšç±»ä¸­å¿ƒæ•°
quantizer = faiss.IndexFlatL2(vector_dim)  # åŸºç¡€é‡åŒ–å™¨
index_ivf = faiss.IndexIVFFlat(quantizer, vector_dim, nlist, faiss.METRIC_L2)
index_ivf.train(database_vectors)
index_ivf.add(database_vectors)

# PQï¼ˆä¹˜ç§¯é‡åŒ–ï¼‰
m = 16  # å­ç©ºé—´æ•°
index_pq = faiss.IndexPQ(vector_dim, m, 8)
index_pq.train(database_vectors)
index_pq.add(database_vectors)

# IVF + PQï¼ˆç²—é‡åŒ– + æ®‹å·® PQï¼‰
index_ivfpq = faiss.IndexIVFPQ(quantizer, vector_dim, nlist, m, 8)
index_ivfpq.train(database_vectors)
index_ivfpq.add(database_vectors)

# -------------------------------
# Step 3: æŸ¥è¯¢å‡½æ•°
# -------------------------------
def run_search(index, name, queries, topk=5):
    print(f"\nğŸ” {name} æ£€ç´¢ç»“æœ")
    if hasattr(index, 'nprobe'):
        index.nprobe = 10  # æ§åˆ¶æ£€ç´¢çš„èšç±»æ•°é‡
    D, I = index.search(queries, topk)
    for i in range(len(queries)):
        print(f"Query {i+1} Top-{topk} indices: {I[i]}, distances: {np.round(D[i], 3)}")

# -------------------------------
# Step 4: æµ‹è¯•æŸ¥è¯¢
# -------------------------------
run_search(index_ivf, "IVF èšç±»é‡åŒ–", query_vectors)
run_search(index_pq, "PQ ä¹˜ç§¯é‡åŒ–", query_vectors)
run_search(index_ivfpq, "IVF+PQ ç²—é‡+æ®‹å·®é‡åŒ–", query_vectors)
