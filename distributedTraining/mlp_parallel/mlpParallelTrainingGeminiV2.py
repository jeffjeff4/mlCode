####sometimes runnable, sometimes stuck
####python raw implementation, implement raw python code, simple MLP çš„training loopï¼Œwith data parallel, tensor parallel.
####please generate data X, Y, and code to use the above DP and tensor parallel code
####
####è¯·ï¼š
####1. æŠŠè¿™ä¸ªä»£ç  æ”¹æˆæ”¯æŒ Adam ä¼˜åŒ–å™¨ã€
####2. TP å°½é‡ä¸ŽçœŸå®žçš„åˆ‡åˆ†æ–¹å¼ä¸€è‡´ï¼Œ çœŸå®žçŽ¯å¢ƒä¸­æ˜¯W1æŒ‰åˆ—åˆ‡ï¼ŒW2æŒ‰è¡Œåˆ‡
####ç¬¬ä¸€å±‚æƒé‡çŸ©é˜µ W1 æŒ‰åˆ—åˆ‡åˆ†ï¼ˆcolumn-wise partitioningï¼‰ã€‚
####ç¬¬äºŒå±‚æƒé‡çŸ©é˜µ W2 æŒ‰è¡Œåˆ‡åˆ†ï¼ˆrow-wise partitioningï¼‰ã€‚
####3. è¿™é‡Œç”¨ multiprocessing.Process + Queue è¿›è¡Œè¿›ç¨‹é—´é€šä¿¡ï¼ˆé€‚åˆæ•™å­¦ï¼‰ã€‚
####4. å¯ä»¥ä¸ä½¿ç”¨çœŸå®žæ¡†æž¶ä¸­ä¼šç”¨æ›´é«˜æ•ˆçš„é€šä¿¡ï¼ˆNCCL / AllGather / AllReduceï¼‰ã€‚
####   å¯ä»¥ä¸ä½¿ç”¨çœŸå®žéƒ¨ç½²åœ¨å¤š GPU ä¸Šä¼šä½¿ç”¨ GPU é€šä¿¡åº“ã€å…±äº«å†…å­˜ã€æ¢¯åº¦åŽ‹ç¼©ç­‰æŠ€å·§ã€‚
####5. è¯·ä¸è¦ä½¿ç”¨queueï¼Œä½¿ç”¨ç®€å•çš„æ–¹æ³•æ¥æ¨¡æ‹Ÿgpuä¹‹é—´çš„æ•°æ®äº¤äº’
####6. è¯·æ¨¡æ‹Ÿä½¿ç”¨2å—GPU
####7. è¯·æŠŠè¿™ä¸ª å¯è§†åŒ–å›¾è§£ï¼ˆç”¨ ascii blockï¼‰é›†æˆåˆ°ä¹‹å‰å†™çš„æ•™å­¦ä»£ç é‡Œï¼Œè¿™æ ·è·‘çš„æ—¶å€™å°±èƒ½çœ‹åˆ°çŸ©é˜µæ€Žä¹ˆåˆ‡åˆ†ã€æ•°æ®æ€Žä¹ˆæµåŠ¨ã€‚è¯·åŒ…æ‹¬forward propagation, backward propagation
####8. è¯·äº§ç”Ÿç±»ä¼¼å¦‚ä¸‹çš„æµç¨‹å›¾ï¼š
####=== Tensor Parallel Training with Adam ===
####
####TP Visualization - W1 Split (Column-Wise):
####
####  X (64 x 784)
####    |
####    v
####+---------+
####| W1      |
####| 784 x 256|
####+---------+
####Split column-wise:
####+---------+---------+
####| Device 0| Device 1|
####| 784 x 128| 784 x 128|
####+---------+---------+
####    |         |
####    v         v
#### A1_part0  A1_part1 (64 x 128)
#### (64 x 128)
#### (No All-Gather for A1; used locally for Z2_local)
####
####
####TP Visualization - W2 Split (Row-Wise):
####
#### A1_part (64 x 128)
####    |
####    v
####+---------+
####| W2      |
####| 256 x 10|
####+---------+
####Split row-wise:
####+---------+
####| Device 0|
####| 128 x 10|
####+---------+
####+---------+
####| Device 1|
####| 128 x 10|
####+---------+
####    |
####    v
#### Z2_local0 (64 x 10)
####    |
####    v
#### Z2_local1 (64 x 10)
####    |
####    +--------+
####      All-Reduce (sum)
####        |
####        v
#### Z2 (64 x 10)
####
####
####TP Visualization - Backward Flow:
####
#### dZ2 (64 x 10)
####    |
####    v
####dA1_local = dZ2 @ W2_part.T (64 x 128)
####    |
####    +--------+
####      All-Gather (concat)
####        |
####        v
#### dA1 (64 x 256)
####Split to dA1_slice (64 x 128)
####    |
####    v
#### dZ1_part = dA1_slice * relu_deriv (64 x 128)
####    |
####    v
#### dW1_part = X.T @ dZ1_part / m (784 x 128)
#### dW2_part = A1_part.T @ dZ2 / m (128 x 10)
####
####
####çœŸå®žçŽ¯å¢ƒä¸­ä¸æ˜¯W1æŒ‰åˆ—åˆ‡ï¼ŒW2æŒ‰è¡Œåˆ‡å—ï¼Ÿè¿™ä¸ªcodeæ˜¯æŒ‰ç…§W1æŒ‰åˆ—åˆ‡ï¼ŒW2æŒ‰è¡Œåˆ‡çš„æ–¹å¼æ¥çš„å—ï¼Ÿ
####
####torch.chunk(W1, tp_size, dim=1)
####
####è¯·æŠŠè¿™ä¸ª å¯è§†åŒ–å›¾è§£ï¼ˆç”¨ ascii blockï¼‰é›†æˆåˆ°ä¹‹å‰å†™çš„æ•™å­¦ä»£ç é‡Œï¼Œè¿™æ ·è·‘çš„æ—¶å€™å°±èƒ½çœ‹åˆ°çŸ©é˜µæ€Žä¹ˆåˆ‡åˆ†ã€æ•°æ®æ€Žä¹ˆæµåŠ¨ï¼Ÿ

####-------------------------------------------------------------------------------------
####çœŸå®žçŽ¯å¢ƒä¸­ä¸æ˜¯W1æŒ‰åˆ—åˆ‡ï¼ŒW2æŒ‰è¡Œåˆ‡å—ï¼Ÿä¸Šé¢è¿™ä¸ªcodeæ˜¯æŒ‰ç…§W1æŒ‰åˆ—åˆ‡ï¼ŒW2æŒ‰è¡Œåˆ‡çš„æ–¹å¼æ¥çš„å—ï¼Ÿ
####
####
####å¯¹ï¼Œä½ çš„ç†è§£æ˜¯å¯¹çš„ âœ…ã€‚â€¨åœ¨ çœŸå®žçš„ Tensor Parallel (TP) å®žçŽ°é‡Œï¼ˆæ¯”å¦‚ Megatron-LMï¼‰ï¼Œå¸¸è§çš„åˆ‡åˆ†æ–¹å¼æ˜¯ï¼š
####W1ï¼ˆè¾“å…¥å±‚ â†’ éšå±‚ï¼‰ï¼š
####W1 çš„ åˆ—åˆ‡åˆ†ï¼ˆcolumn parallelismï¼‰
####æ¯ä¸ª rank è´Ÿè´£ä¸€éƒ¨åˆ† è¾“å‡ºç»´åº¦ã€‚
####ä¼˜ç‚¹ï¼šè¾“å…¥ X å¯ä»¥å¹¿æ’­åˆ°æ‰€æœ‰ rankï¼Œå„è‡ªç®— X @ W1_shardï¼Œå¾—åˆ°çš„æ˜¯å¯¹åº” shard çš„éƒ¨åˆ† hiddenã€‚æœ€åŽå†æ‹¼èµ·æ¥ã€‚
####W2ï¼ˆéšå±‚ â†’ è¾“å‡ºå±‚ï¼‰ï¼š
####W2 çš„ è¡Œåˆ‡åˆ†ï¼ˆrow parallelismï¼‰
####æ¯ä¸ª rank è´Ÿè´£ä¸€éƒ¨åˆ† è¾“å…¥ç»´åº¦ã€‚
####ä¼˜ç‚¹ï¼šæ¯ä¸ª rank åªå­˜å‚¨éƒ¨åˆ† hidden çš„å‚æ•°ï¼Œforward æ—¶å„è‡ªå¤„ç† shardï¼Œå¯¹è¾“å‡ºåš AllReduceï¼ˆå› ä¸ºæœ€ç»ˆè¾“å‡ºè¦æ•´åˆæ‰€æœ‰ shard çš„è´¡çŒ®ï¼‰ã€‚
####
####ðŸ”Ž ä½ æåˆ°çš„æˆ‘çš„ç¤ºä¾‹ä»£ç 
####æˆ‘ä¹‹å‰ç»™ä½ çš„æ•™å­¦ç‰ˆä»£ç ï¼Œç¡®å®žæ˜¯è¿™æ ·åˆ‡çš„ï¼š
####W1 æ˜¯ torch.randn(D_in, D_hidden)ï¼Œåœ¨æž„é€ æ—¶æˆ‘ç”¨äº† åˆ—åˆ‡ â†’ torch.chunk(W1, tp_size, dim=1)ã€‚â€¨âœ” è¿™å°±æ˜¯ â€œW1 æŒ‰åˆ—åˆ‡â€ã€‚
####W2 æ˜¯ torch.randn(D_hidden, D_out)ï¼Œåœ¨æž„é€ æ—¶æˆ‘ç”¨äº† è¡Œåˆ‡ â†’ torch.chunk(W2, tp_size, dim=0)ã€‚â€¨âœ” è¿™å°±æ˜¯ â€œW2 æŒ‰è¡Œåˆ‡â€ã€‚
####æ‰€ä»¥å’Œä½ è¯´çš„ çœŸå®žçŽ¯å¢ƒå¸¸è§åšæ³•æ˜¯ä¸€è‡´çš„ã€‚
####
####è¦ä¸è¦æˆ‘å¸®ä½ åœ¨ä»£ç é‡ŒåŠ ä¸€æ®µ å›¾ç¤ºï¼ˆçŸ©é˜µåˆ‡åˆ†å¯è§†åŒ–ï¼‰ï¼Œè¿™æ ·å¯ä»¥æ¸…æ¥šçœ‹åˆ°ï¼š
####W1 å¦‚ä½•æŒ‰åˆ—åˆ‡åˆ†
####W2 å¦‚ä½•æŒ‰è¡Œåˆ‡åˆ†â€¨ä»¥åŠ forward/backward ä¸­å„ä¸ª shard çš„æ•°æ®æµï¼Ÿ
####
####
####
####å¥½ ðŸ‘Œ æˆ‘æ¥å¸®ä½ æŠŠ Tensor Parallel çš„çŸ©é˜µåˆ‡åˆ†æ–¹å¼ ç”¨å›¾ç¤ºç›´è§‚å±•ç¤ºä¸€ä¸‹ã€‚
####
####ðŸ”¹ 1. W1 æŒ‰åˆ—åˆ‡åˆ†ï¼ˆColumn Parallelï¼‰
####è®¾è¾“å…¥å±‚ç»´åº¦æ˜¯ D_inï¼Œéšå±‚ç»´åº¦æ˜¯ D_hiddenã€‚â€¨æƒé‡çŸ©é˜µ W1 çš„å½¢çŠ¶æ˜¯ (D_in, D_hidden)ã€‚
####æ­£å¸¸æƒ…å†µï¼š
####
####X (N, D_in)  @  W1 (D_in, D_hidden)  â†’  H (N, D_hidden)
####åˆ—åˆ‡åˆ†ï¼š
####
####W1 è¢«æŒ‰åˆ—åˆ‡åˆ† â†’ æ¯ä¸ª rank æ‹¿ä¸€éƒ¨åˆ† hidden
####ä¾‹å­ï¼šâ€¨å‡è®¾ D_in = 4, D_hidden = 6, åˆ‡æˆ 2 ä»½ï¼š
####
####         W1 (4x6)
####   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
####   â”‚      Rank0    â”‚      Rank1
####   â”‚   (4x3 cols)  â”‚   (4x3 cols)
####   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
####æ¯ä¸ª rank ç®—ï¼š
####
####H0 = X @ W1_shard0   â†’ (N, 3)
####H1 = X @ W1_shard1   â†’ (N, 3)
####æœ€åŽæ‹¼æŽ¥ï¼š
####
####H = [H0 | H1]  â†’ (N, 6)
####
####ðŸ”¹ 2. W2 æŒ‰è¡Œåˆ‡åˆ†ï¼ˆRow Parallelï¼‰
####è®¾éšå±‚ç»´åº¦æ˜¯ D_hiddenï¼Œè¾“å‡ºå±‚ç»´åº¦æ˜¯ D_outã€‚â€¨æƒé‡çŸ©é˜µ W2 çš„å½¢çŠ¶æ˜¯ (D_hidden, D_out)ã€‚
####æ­£å¸¸æƒ…å†µï¼š
####
####H (N, D_hidden)  @  W2 (D_hidden, D_out)  â†’  Y (N, D_out)
####è¡Œåˆ‡åˆ†ï¼š
####
####W2 è¢«æŒ‰è¡Œåˆ‡åˆ† â†’ æ¯ä¸ª rank æ‹¿ä¸€éƒ¨åˆ†è¾“å…¥ hidden
####ä¾‹å­ï¼šâ€¨å‡è®¾ D_hidden = 6, D_out = 2, åˆ‡æˆ 2 ä»½ï¼š
####
####         W2 (6x2)
####   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
####   â”‚ Rank0 â”‚  (3x2 rows)
####   â”‚ Rank1 â”‚  (3x2 rows)
####   â””â”€â”€â”€â”€â”€â”€â”€â”˜
####æ¯ä¸ª rank ç®—ï¼š
####
####Y0 = H[:, :3] @ W2_shard0   â†’ (N, 2)
####Y1 = H[:, 3:] @ W2_shard1   â†’ (N, 2)
####æœ€åŽ åŠ å’Œ (AllReduce)ï¼š
####
####Y = Y0 + Y1   â†’ (N, 2)
####
####ðŸ”¹ 3. æ€»ç»“æ•°æ®æµ
####
####X â”€â”€â–º W1 (col split) â”€â”€â–º æ‹¼æŽ¥ H â”€â”€â–º W2 (row split) â”€â”€â–º AllReduce â”€â”€â–º Y
####W1ï¼šåˆ—åˆ‡ â†’ è¾“å‡ºæ‹¼æŽ¥ï¼ˆConcatï¼‰
####W2ï¼šè¡Œåˆ‡ â†’ è¾“å‡ºæ±‚å’Œï¼ˆReduceï¼‰
####
####è¦ä¸è¦æˆ‘ç›´æŽ¥æŠŠè¿™ä¸ª å¯è§†åŒ–å›¾è§£ï¼ˆç”¨ matplotlib æˆ– ascii blockï¼‰é›†æˆåˆ°æˆ‘ä¹‹å‰å†™çš„æ•™å­¦ä»£ç é‡Œï¼Œè¿™æ ·ä½ è·‘çš„æ—¶å€™å°±èƒ½çœ‹åˆ°çŸ©é˜µæ€Žä¹ˆåˆ‡åˆ†ã€æ•°æ®æ€Žä¹ˆæµåŠ¨ï¼Ÿ
####
####
####
####è¯·åŠ åå‘ä¼ æ’­çš„ ascii blockï¼Œæ˜¾ç¤º grad_W1 å’Œ grad_W2 æ˜¯æ€Žä¹ˆåˆå¹¶çš„
####
####
####
####å¥½ âœ…â€¨åœ¨å‰å‘æˆ‘ä»¬å·²ç»ç”»äº† W1 åˆ—åˆ‡ / W2 è¡Œåˆ‡ï¼ŒçŽ°åœ¨æˆ‘æ¥å¸®ä½ è¡¥ä¸Š åå‘ä¼ æ’­çš„ ascii blockï¼Œå¹¶ä¸”æŠŠå®ƒé›†æˆåˆ°ä»£ç é‡Œã€‚è¿™æ ·ä¸€è·‘ï¼Œä¸å…‰èƒ½çœ‹åˆ° forward çš„æ•°æ®æµï¼Œè¿˜èƒ½çœ‹åˆ° backward çš„æ¢¯åº¦æµã€‚
####
####ðŸ”¹ åå‘ä¼ æ’­ç›´è§‚é€»è¾‘
####Loss å¯¹è¾“å‡ºçš„æ¢¯åº¦
####
####dL/dY  (N, D_out)
####W2ï¼ˆè¡Œåˆ‡åˆ†ï¼‰çš„åä¼ 
####forward æ—¶ W2 æ˜¯ è¡Œåˆ‡ â†’ æ¯ä¸ª rank è´Ÿè´£ä¸€éƒ¨åˆ† hidden â†’ åä¼ æ—¶æ¯ä¸ª rank åªæ”¶åˆ°å¯¹åº” shard çš„ grad_H_localã€‚
####
####grad_W2_rank = H_localáµ€ @ dL/dY
####grad_H_local = dL/dY @ W2_shardáµ€
####æœ€åŽï¼š
####
####grad_W2 = sum(grad_W2_rank)   (è¡Œæ‹¼èµ·æ¥)
####grad_H  = concat(grad_H_local)  (åˆ—æ‹¼èµ·æ¥)
####W1ï¼ˆåˆ—åˆ‡åˆ†ï¼‰çš„åä¼ 
####forward æ—¶ W1 æ˜¯ åˆ—åˆ‡ â†’ æ¯ä¸ª rank åªè®¡ç®—éƒ¨åˆ† H â†’ backward æ—¶è¦ sum å„ä¸ª shard å¯¹è¾“å…¥çš„æ¢¯åº¦è´¡çŒ®ï¼š
####
####grad_W1_rank = Xáµ€ @ grad_H_local
####grad_X       = sum_over_ranks(grad_H_local @ W1_shardáµ€)
####æœ€åŽï¼š
####
####grad_W1 = sum(grad_W1_rank)


import torch
import torch.nn as nn
import torch.optim as optim
import multiprocessing
import numpy as np
import copy
from typing import Tuple

# Global variable to simulate shared memory for communication.
# Use this with caution, as it is a simplified model.
shared_data_list = None


def generate_data(num_samples: int = 256,
                  input_dim: int = 128,
                  output_dim: int = 1) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    Generates synthetic data for a simple MLP.
    """
    print("Generating synthetic data...")
    X = torch.randn(num_samples, input_dim)
    # A simple linear relationship with some noise.
    Y = torch.randn(num_samples, output_dim) * 0.1 + torch.sum(X, dim=1, keepdim=True) * 0.5
    print(f"Data generated. X shape: {X.shape}, Y shape: {Y.shape}")
    return X, Y


class MLP(nn.Module):
    """
    A simple Multi-Layer Perceptron model for single-device and DP.
    """

    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_dim, output_dim)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x


def single_device_train(X: torch.Tensor, Y: torch.Tensor, device: torch.device):
    """
    Implements a single-device training loop.
    """
    print("\n--- Start Single-Device Training ---")
    model = MLP(X.shape[1], 128, Y.shape[1]).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.01)

    for epoch in range(5):
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, Y)
        loss.backward()
        optimizer.step()
        print(f"Single-Device | Epoch {epoch + 1}/5 | Loss: {loss.item():.4f}")

    print("--- Single-Device Training Finished ---")


def data_parallel_train(X_data: torch.Tensor, Y_data: torch.Tensor, rank: int, world_size: int, shared_data_list):
    """
    Implements a Data Parallel training loop for a single process.
    """
    if rank == 0:
        print("""
            --------------------
            | Data Parallelism |
            --------------------

            +-----------+            +-----------+
            |  Data (X) |            |   Model   |
            |   [1..N]  |            |  (Copy)   |
            +-----------+            +-----+-----+
                  |                        |
                  | Split Data             | Replicate Model
                  V                        V
      +-----------+           +------------+------------+
      |  Data (X1) |  ->  | Model (Copy 1) | -> Gradients (G1)
      +-----------+           +------------+------------+
      |  Data (X2) |  ->  | Model (Copy 2) | -> Gradients (G2)
      +-----------+           +------------+------------+
      |  ...      |           |   ...      | -> ...
      +-----------+           +------------+------------+
                                     |
                                     | All-Reduce & Average Gradients
                                     V
                           +------------------+
                           |  Updated Model   |
                           +------------------+
        """)

    print(f"\n--- Process {rank}: Running Data Parallel Training ---")

    batch_size = X_data.shape[0] // world_size
    start_idx = rank * batch_size
    end_idx = start_idx + batch_size
    X_part = X_data[start_idx:end_idx]
    Y_part = Y_data[start_idx:end_idx]

    print(f"Process {rank} handles data from index {start_idx} to {end_idx - 1}, shape {X_part.shape}")

    model = MLP(X_part.shape[1], 128, Y_part.shape[1])
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.01)

    for epoch in range(5):
        optimizer.zero_grad()
        outputs = model(X_part)
        loss = criterion(outputs, Y_part)
        loss.backward()

        # Simulate All-Reduce for Gradients
        shared_data_list.append({name: p.grad.detach() for name, p in model.named_parameters()})

        # Wait for all processes to finish putting gradients
        while len(shared_data_list) < world_size * (epoch + 1):
            pass

        # Process 0 acts as the master to average gradients
        if rank == 0:
            sum_grads = copy.deepcopy(shared_data_list[epoch * world_size])
            for i in range(1, world_size):
                other_grads = shared_data_list[epoch * world_size + i]
                for name, grad in other_grads.items():
                    sum_grads[name] += grad

            for name, param in model.named_parameters():
                param.grad = sum_grads[name] / world_size

            optimizer.step()
            print(f"Data Parallel | Epoch {epoch + 1}/5 | Total Loss: {loss.item():.4f}")
        else:
            # For this simple demo, other processes just wait.
            pass


def tensor_parallel_train(X_data: torch.Tensor, Y_data: torch.Tensor, rank: int, world_size: int, shared_data_list):
    """
    Implements a Tensor Parallel training loop for a single process using a Master-Worker pattern.
    """
    print(f"\n--- Process {rank}: Running Tensor Parallel Training ---")

    input_dim = X_data.shape[1]
    hidden_dim = 128
    output_dim = Y_data.shape[1]

    assert hidden_dim % world_size == 0, "Hidden dim must be divisible by world size."
    hidden_dim_part = hidden_dim // world_size

    # Manually create model weights for each partition.
    W1_part = torch.randn(input_dim, hidden_dim_part, requires_grad=True)
    b1_part = torch.zeros(hidden_dim_part, requires_grad=True)

    W2_part = torch.randn(hidden_dim_part, output_dim, requires_grad=True)
    b2 = torch.zeros(output_dim, requires_grad=True)

    optimizer = optim.Adam([W1_part, W2_part, b1_part, b2], lr=0.01)
    criterion = nn.MSELoss()

    for epoch in range(5):
        optimizer.zero_grad()

        # --- Forward Pass (local computation) ---
        Y_part = torch.matmul(X_data, W1_part) + b1_part
        Y_part = nn.functional.relu(Y_part)
        Z_part = torch.matmul(Y_part, W2_part) + b2

        # --- Master-Worker Communication ---
        # Master process (rank 0) collects all Z_parts.
        if rank == 0:
            # Master gets its own Z_part
            all_Z_parts = [Z_part]
            # Master waits for and collects Z_parts from all workers.
            while len(shared_data_list) < world_size - 1:
                pass
            all_Z_parts.extend(shared_data_list[:])
            shared_data_list[:] = []  # Clear the list for next epoch.

            # Master sums all Z_parts to get Z_full.
            Z_full = sum(all_Z_parts)
            loss = criterion(Z_full, Y_data)

            # Master computes the gradient of the loss and sends it to workers.
            # IMPORTANT: Detach the gradient tensor before sending!
            dZ_full = (2 * (Z_full - Y_data) / X_data.shape[0]).detach()
            for _ in range(world_size - 1):
                shared_data_list.append(dZ_full)

        else:  # Worker process
            # Worker sends its detached Z_part to the master.
            shared_data_list.append(Z_part.detach())

            # Worker waits for master to send back the dZ_full.
            while len(shared_data_list) == 0:
                pass
            dZ_full = shared_data_list.pop(0)

        # --- Manual Backward Pass (local computation) ---
        # Each process uses the shared dZ_full to compute local gradients.

        # 1. dW2_part and db2 (local computation)
        dW2_part = Y_part.T @ dZ_full
        db2 = torch.sum(dZ_full, dim=0)

        # 2. dY_part (local computation)
        dY_part = dZ_full @ W2_part.T

        # 3. dW1_part and db1_part (local computation)
        dW1_part = X_data.T @ dY_part
        db1_part = torch.sum(dY_part, dim=0)

        # --- Optimization Step ---
        # Apply the gradients manually and update weights.
        W1_part.grad = dW1_part
        b1_part.grad = db1_part
        W2_part.grad = dW2_part
        b2.grad = db2

        optimizer.step()

        if rank == 0:
            print(f"Tensor Parallel | Epoch {epoch + 1}/5 | Total Loss: {loss.item():.4f}")

        # --- Backward Pass Visualization ---
        if rank == 0:
            print("\nTP Visualization - Backward Pass:")
            print(f"""
            ========================================================
            |       Backward Pass with Gradients All-Reduce      |
            ========================================================
            Loss: {loss.item():.4f}
                    |
                    v
            dZ_full (Full Gradient): {tuple(dZ_full.shape)}
                    |
                    v
            dW2_part0 = Y_part0.T @ dZ_full
            dW2_part1 = Y_part1.T @ dZ_full

            +--------------------+--------------------+
            | dW2_part0: {tuple(W2_part.shape)} | dW2_part1: {tuple(W2_part.shape)} |
            +--------------------+--------------------+


            ========================================================
            |   All-Gather for dY (Hidden Layer Gradient)      |
            ========================================================

            dY_part0 = dZ_full @ W2_part0.T
            dY_part1 = dZ_full @ W2_part1.T

            +--------------------+--------------------+
            | dY_part0: {tuple(dY_part.shape)} | dY_part1: {tuple(dY_part.shape)} |
            +--------------------+--------------------+
                    |                     |
                    +---- All-Gather (Concat) ----+
                                |
                                v
                    dY_full: {tuple(dY_part.shape)}


            ========================================================
            |     dW1 Gradient Calculation (Local)           |
            ========================================================

            dW1_part0 = X.T @ dY_part0
            dW1_part1 = X.T @ dY_part1

            +--------------------+--------------------+
            | dW1_part0: {tuple(W1_part.shape)} | dW1_part1: {tuple(W1_part.shape)} |
            +--------------------+--------------------+
            """)


if __name__ == '__main__':
    multiprocessing.set_start_method('spawn', force=True)

    manager = multiprocessing.Manager()
    shared_data_list = manager.list()

    INPUT_DIM = 128
    OUTPUT_DIM = 1
    X, Y = generate_data(input_dim=INPUT_DIM, output_dim=OUTPUT_DIM)

    device = torch.device('cpu')
    X, Y = X.to(device), Y.to(device)

    single_device_train(X, Y, device)

    world_size_dp = 2
    print(f"\n{'=' * 50}\nBeginning Data Parallel Training on {world_size_dp} processes.\n{'=' * 50}")
    processes_dp = []
    for rank in range(world_size_dp):
        p = multiprocessing.Process(target=data_parallel_train,
                                    args=(X, Y, rank, world_size_dp, shared_data_list))
        processes_dp.append(p)
        p.start()
    for p in processes_dp:
        p.join()

    shared_data_list[:] = []

    world_size_tp = 2
    print(f"\n{'=' * 50}\nBeginning Tensor Parallel Training on {world_size_tp} processes.\n{'=' * 50}")
    processes_tp = []
    for rank in range(world_size_tp):
        p = multiprocessing.Process(target=tensor_parallel_train,
                                    args=(X, Y, rank, world_size_tp, shared_data_list))
        processes_tp.append(p)
        p.start()
    for p in processes_tp:
        p.join()
